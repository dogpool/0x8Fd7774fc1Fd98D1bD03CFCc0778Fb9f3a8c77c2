{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CPFB-AppliedMachineLearningProject3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dogpool/0x8Fd7774fc1Fd98D1bD03CFCc0778Fb9f3a8c77c2/blob/main/CPFB_NortheasternUniversityAppliedMachineLearningProject3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JisRkUITF_8C"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aeSdWYS9AFW"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "import os\n",
        "from numpy import sort\n",
        "from xgboost import XGBRegressor\n",
        "from xgboost import plot_tree\n",
        "from xgboost import plot_importance\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score, StratifiedKFold\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import itertools\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import metrics\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.tree import export_graphviz\n",
        "import pydot\n",
        "from pprint import pprint\n",
        "#hyperparameter tuning\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "dataset = pd.read_csv('CFPB-financial-wellness-data.csv')\n",
        "dataset.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "issZw3ZPl7Za"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ct_yl5KGAh9"
      },
      "source": [
        "*https://github.com/WillKoehrsen/Data-Analysis/tree/master/random_forest_explained*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPaO0gEql4Oj"
      },
      "source": [
        "# **Load & Understand the Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QP3Aw7WOGBTL"
      },
      "source": [
        "dataset.dtypes\n",
        "dataset.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfkPb0PGl8iJ"
      },
      "source": [
        "dataset[['PRODUSE_3']].describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wO91C8tkDZpt"
      },
      "source": [
        "dataset.hist(bins=30, figsize=(15,10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZjSSTw9mQJ7"
      },
      "source": [
        "dataset = dataset.drop(['CONNECT',''], axis=1)\n",
        "a.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVVaayYFDZ-k"
      },
      "source": [
        "dataset['ABSORBSHOCK'].describe()\n",
        "dataset['MANAGE_1'].describe()\n",
        "dataset['MANAGE_3'].describe()\n",
        "dataset['FINSOC2_3'].describe()\n",
        "dataset['rejected_1'].describe()\n",
        "dataset['FRAUD2'].describe()\n",
        "dataset['PPT01'].describe()\n",
        "dataset['PPT25'].describe()\n",
        "dataset['PPT612'].describe()\n",
        "dataset['KHKNOWL7'].describe()\n",
        "dataset['KH7CORRECT'].describe()\n",
        "dataset['FWB1_6'].describe()\n",
        "dataset['FS1_6'].describe()\n",
        "dataset['SAVEHABIT'].describe()\n",
        "dataset['CONSPROTECT1'].describe()\n",
        "dataset['FINSOC2_7'].describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FDq8mKRDaSa"
      },
      "source": [
        "# Split the data into X & y, and testing and training data\n",
        "x = dataset['ABSORBSHOCK', 'MANAGE_1', 'MANAGE_3', 'FINSOC2_3', 'REJECTED_1', 'REJECTED_2', 'FRAUD2', 'PPT01', 'PPT25', 'PPT612', 'KHKNOWL7', 'KH7CORRECT', 'FWB1_6', 'SAVEHABIT', 'CONSPROTECT1', 'FINSOC2_7' ]\n",
        "y = dataset['PRODUSE_3']\n",
        "\n",
        "X_train,X_test, y_train, y_test = train_test_split(X, y, test_size = 30, random_state=0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pd-Hsb5chY3v"
      },
      "source": [
        "# Correlations\n",
        "\n",
        "plt.figure(figsize=(30,15)) \n",
        "sns.heatmap(dataset.drop(columns = ['PRODUSE_3'], axis = 1).corr(), annot=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dK1UMgBfiCfb"
      },
      "source": [
        "# **XGBOOST MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OtBB6ImhYtY"
      },
      "source": [
        "# XGBoost Regression Model\n",
        "\n",
        "xgb_model = XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
        "             colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
        "             importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
        "             max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
        "             n_jobs=1, nthread=None, objective='reg:squarederror', random_state=0,\n",
        "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
        "             silent=None, subsample=1, verbosity=1)\n",
        "xgb_model.fit(X_train, y_train)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLWSRblNh96G"
      },
      "source": [
        "# Training Score\n",
        "from sklearn import metrics\n",
        "training_score = xgb_model.score(X_train, y_train)\n",
        "print(training_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4qRQQ9Dh-HN"
      },
      "source": [
        "# MSE and RMSE\n",
        "y_pred = xgb_model.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"MSE: \", mse)\n",
        "print('RMSE: ', mse**0.5) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zM8V42YDiZnr"
      },
      "source": [
        "# Plot predicted vs actual \n",
        "x_axis = range(len(y_test))\n",
        "plt.plot(x_axis, y_test, label = 'Original Data')\n",
        "plt.plot(x_axis, y_pred, label = 'Predict')\n",
        "plt.title('Financial Wellbeing Survey test and predicted data (XGBoost)')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocJN8Bvqh-YA"
      },
      "source": [
        "plt.barh(['ABSORBSHOCK', 'MANAGE_1', 'MANAGE_3', 'FINSOC2_3', 'REJECTED_1', 'REJECTED_2', 'FRAUD2', 'PPT01', \n",
        "          'PPT25', 'PPT612', 'KHKNOWL7', 'KH7CORRECT', 'FWB1_6', 'SAVEHABIT', 'CONSPROTECT1', 'FINSOC2_7'],  xgb_model.feature_importances_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4_uERnDk2ab"
      },
      "source": [
        "# **SVM MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tt6TgNaQiZ-Q"
      },
      "source": [
        "from sklearn.svm import SVR \n",
        "\n",
        "#creating model\n",
        "svr = SVR()\n",
        "# fit the model\n",
        "svr.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkVy1nANk1vm"
      },
      "source": [
        "# Training Score\n",
        "from sklearn import metrics\n",
        "training_score1 = svr.score(X_train, y_train)\n",
        "print(training_score1)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFTsAaKvlFjA"
      },
      "source": [
        "# Predict y_pred, and print error measurements\n",
        "y_pred = svr.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"MSE: \", mse)\n",
        "print('RMSE: ', mse**0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYG7xWnFlUL5"
      },
      "source": [
        "# **Random Forest MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFhrSPQzlYiO"
      },
      "source": [
        "# forestclassifier in order find best N features\n",
        "all_predictors_columns = [col for col in dataset.columns if col != 'PRODUSE_3']\n",
        "\n",
        "all_predictors = dataset[all_predictors_columns]\n",
        "#all the predictors\n",
        "all_predictors.describe()\n",
        "\n",
        "w = 1000\n",
        "\n",
        "sel = SelectFromModel(RandomForestClassifier(n_estimators = 1000, class_weight={0:1, 1:w}), threshold='2*mean')\n",
        "sel.fit(all_predictors, target)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fo8p0FeRlYun"
      },
      "source": [
        "sel.get_support()\n",
        "selected_feat= all_predictors.columns[(sel.get_support())]\n",
        "len(selected_feat)\n",
        "selected_feat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYtTHkZWlY-Z"
      },
      "source": [
        "x_fpredictors = a[['ABSORBSHOCK', 'MANAGE_1', 'MANAGE_3', 'FINSOC2_3', 'REJECTED_1', 'REJECTED_2', 'FRAUD2', 'PPT01', 'PPT25', \n",
        "                   'PPT612', 'KHKNOWL7', 'KH7CORRECT', 'FWB1_6', 'SAVEHABIT', 'CONSPROTECT1', 'FINSOC2_7']]\n",
        "\n",
        "\n",
        "X_train,X_test, y_train, y_test = train_test_split(x_fpredictors ,target, test_size = 0.40, random_state = 7)\n",
        "print(\"x_train \",X_train.shape)\n",
        "print(\"x_test \",X_test.shape)\n",
        "print(\"y_train \",y_train.shape)\n",
        "print(\"y_test \",y_test.shape)\n",
        "\n",
        "w=10000\n",
        "\n",
        "classifier = RandomForestClassifier(bootstrap = True, \n",
        "                                    n_estimators = 100, \n",
        "                                    criterion = 'entropy', \n",
        "                                    min_samples_leaf = 3,\n",
        "                                    min_samples_split =8,\n",
        "                                    class_weight={0:1, 1:w},\n",
        "                                    max_depth = 40,\n",
        "                                    max_features = 5,\n",
        "                                    oob_score = True, \n",
        "                                    n_jobs = -1 )\n",
        "\n",
        "model_RF = classifier.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DV_BCd0n4hU"
      },
      "source": [
        "acc_random_forest = round(classifier.score(X_test, y_test) * 100, 2)\n",
        "print(\"Model accuracy is: \", acc_random_forest, \"%\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfowAbaJn965"
      },
      "source": [
        "y_pred_proba = model_RF.predict_proba(X_test)[:,1]\n",
        "y_pred_proba"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-I1OQCf0oJEr"
      },
      "source": [
        "fpr, tpr, t = metrics.roc_curve(y_test,  y_pred_proba) \n",
        "\n",
        "auc = metrics.roc_auc_score(y_test, y_pred_proba)\n",
        "plt.plot(fpr,tpr,label=\"AUC=\"+str(auc))\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ju4ML6xvoJot"
      },
      "source": [
        "y_pred_RF = model_RF.predict(X_test)\n",
        "y_pred_RF.sum()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSoERF-YoP1n"
      },
      "source": [
        "evaluation_scores = pd.Series({'Model': \" Random Forest Classifier \",\n",
        "                 'ROC AUC Score' : metrics.roc_auc_score(y_test, y_pred_proba),\n",
        "                 'Precision Score': metrics.precision_score(y_test, y_pred_RF),\n",
        "                 'Recall Score': metrics.recall_score(y_test, y_pred_RF),\n",
        "                 'Accuracy Score': metrics.accuracy_score(y_test, y_pred_RF)})\n",
        "\n",
        "print(evaluation_scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ci6GU1gFoU6p"
      },
      "source": [
        "#check for overfitting\n",
        "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred_RF))  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTW-1fCJoYgZ"
      },
      "source": [
        "cnf_matrix = confusion_matrix(y_test,y_pred_RF)\n",
        "print(cnf_matrix)\n",
        "\n",
        "\n",
        "cf_df = pd.DataFrame(cnf_matrix,columns=['0','1'],index=['0','1'])\n",
        "sns.set(font_scale=1.4)\n",
        "plt.figure(figsize = (7,5))\n",
        "sns.heatmap(cf_df, annot=True,fmt='5.0f')\n",
        "plt.title('Confusion matrix of the classifier')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05h0K7glofud"
      },
      "source": [
        "feature_importances = pd.Series(classifier.feature_importances_, index=X_train.columns)\n",
        "feature_importances.nlargest(25).plot(kind='barh') #top 10 features\n",
        "\n",
        "plt.show()\n",
        "X_train.head()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}